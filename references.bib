%%% reproducibility crisis

@article{allison2016,
	title = {Reproducibility: {A} tragedy of errors},
	volume = {530},
	copyright = {2016 Nature Publishing Group},
	issn = {1476-4687},
	shorttitle = {Reproducibility},
	url = {https://www.nature.com/articles/530027a},
	doi = {10.1038/530027a},
	abstract = {Mistakes in peer-reviewed papers are easy to find but hard to fix, report David B. Allison and colleagues.},
	language = {en},
	number = {7588},
	urldate = {2023-03-22},
	journal = {Nature},
	author = {Allison, David B. and Brown, Andrew W. and George, Brandon J. and Kaiser, Kathryn A.},
	month = feb,
	year = {2016},
	note = {Number: 7588
Publisher: Nature Publishing Group},
	keywords = {Communication, Peer review, Publishing},
	pages = {27--29}
}

@misc{bastian2016,
	title = {Reproducibility {Crisis} {Timeline}: {Milestones} in {Tackling} {Research} {Reliability}},
	shorttitle = {Reproducibility {Crisis} {Timeline}},
	url = {https://absolutelymaybe.plos.org/2016/12/05/reproducibility-crisis-timeline-milestones-in-tackling-research-reliability/},
	abstract = {It’s not a new story, although “the reproducibility crisis” may seem to be. For life sciences, I think it started in the…},
	language = {en-US},
	urldate = {2023-03-22},
	journal = {Absolutely Maybe (PLOS)},
	author = {Bastian, Hilda},
	month = dec,
	year = {2016}
}

@unpublished{hernandez2023,
	title = {Repeatability, {Reproducibility}, {Replicability}, {Reusability} ({4R}) in {Journals}' {Policies} and {Software}/{Data} {Management} in {Scientific} {Publications}: {A} {Survey}, {Discussion}, and {Perspectives}},
	shorttitle = {Repeatability, {Reproducibility}, {Replicability}, {Reusability} ({4R}) in {Journals}' {Policies} and {Software}/{Data} {Management} in {Scientific} {Publications}},
	url = {https://hal.science/hal-04322522},
	abstract = {With the recognized crisis of credibility in scientific research, there is a growth of reproducibility studies in computer science, and although existing surveys have reviewed reproducibility from various perspectives, especially very specific technological issues, they do not address the author-publisher relationship in the publication of reproducible computational scientific articles. This aspect requires significant attention because it is the basis for reliable research. We have found a large gap between the reproducibility-oriented practices, journal policies, recommendations, publisher artifact Description/Evaluation guidelines, submission guides, technological reproducibility evolution, and its effective adoption to contribute to tackling the crisis. We conducted a narrative survey, a comprehensive overview and discussion identifying the mutual efforts required from Authors, Journals, and Technological actors to achieve reproducibility research. The relationship between authors and scientific journals in their mutual efforts to jointly improve the reproducibility of scientific results is analyzed. Eventually, we propose recommendations for the journal policies, as well as a unified and standardized Reproducibility Guide for the submission of scientific articles for authors. The main objective of this work is to analyze the implementation and experiences of reproducibility policies, techniques and technologies, standards, methodologies, software, and data management tools required for scientific reproducible publications. Also, the benefits and drawbacks of such an adoption, as well as open challenges and promising trends, to propose possible strategies and efforts to mitigate the identified gaps. To this purpose, we analyzed 200 scientific articles, surveyed 16 Computer Science journals, and systematically classified them according to reproducibility strategies, technologies, policies, code citation, and editorial business. We conclude there is still a reproducibility gap in scientific publications, although at the same time also the opportunity to reduce this gap with the joint effort of authors, publishers, and technological providers.},
	urldate = {2024-01-04},
	author = {Hernández, José Armando and Colom, Miguel},
	month = dec,
	year = {2023},
	keywords = {Reproducibility, Data Citation, Data Science AI/ML, RaaS, Repeatability, Replicability, Reproducible Research, Reusability, Rewarding Research, Scientific journal, Trustworthy},
	annote = {working paper or preprint}
}

@article{ioannidis2005,
	title = {Why {Most} {Published} {Research} {Findings} {Are} {False}},
	volume = {2},
	issn = {1549-1277},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1182327/},
	doi = {10.1371/journal.pmed.0020124},
	abstract = {There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research., Published research findings are sometimes refuted by subsequent evidence, says Ioannidis, with ensuing confusion and disappointment.},
	number = {8},
	urldate = {2023-03-22},
	journal = {PLoS Medicine},
	author = {Ioannidis, John P. A.},
	month = aug,
	year = {2005},
	pmid = {16060722},
	pmcid = {PMC1182327},
	pages = {e124}
}

@article{steen2011,
	title = {Retractions in the scientific literature: is the incidence of research fraud increasing?},
	volume = {37},
	copyright = {© 2011, Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions.},
	issn = {0306-6800, 1473-4257},
	shorttitle = {Retractions in the scientific literature},
	url = {https://jme.bmj.com/content/37/4/249},
	doi = {10.1136/jme.2010.040923},
	abstract = {{\textless}h3{\textgreater}Background{\textless}/h3{\textgreater} {\textless}p{\textgreater}Scientific papers are retracted for many reasons including fraud (data fabrication or falsification) or error (plagiarism, scientific mistake, ethical problems). Growing attention to fraud in the lay press suggests that the incidence of fraud is increasing.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Methods{\textless}/h3{\textgreater} {\textless}p{\textgreater}The reasons for retracting 742 English language research papers retracted from the PubMed database between 2000 and 2010 were evaluated. Reasons for retraction were initially dichotomised as fraud or error and then analysed to determine specific reasons for retraction.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater} {\textless}p{\textgreater}Error was more common than fraud (73.5\% of papers were retracted for error (or an undisclosed reason) vs 26.6\% retracted for fraud). Eight reasons for retraction were identified; the most common reason was scientific mistake in 234 papers (31.5\%), but 134 papers (18.1\%) were retracted for ambiguous reasons. Fabrication (including data plagiarism) was more common than text plagiarism. Total papers retracted per year have increased sharply over the decade (r=0.96; p\&lt;0.001), as have retractions specifically for fraud (r=0.89; p\&lt;0.001). Journals now reach farther back in time to retract, both for fraud (r=0.87; p\&lt;0.001) and for scientific mistakes (r=0.95; p\&lt;0.001). Journals often fail to alert the naïve reader; 31.8\% of retracted papers were not noted as retracted in any way.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions{\textless}/h3{\textgreater} {\textless}p{\textgreater}Levels of misconduct appear to be higher than in the past. This may reflect either a real increase in the incidence of fraud or a greater effort on the part of journals to police the literature. However, research bias is rarely cited as a reason for retraction.{\textless}/p{\textgreater}},
	language = {en},
	number = {4},
	urldate = {2023-03-22},
	journal = {Journal of Medical Ethics},
	author = {Steen, R. Grant},
	month = apr,
	year = {2011},
	pmid = {21186208},
	note = {Publisher: Institute of Medical Ethics
Section: Research ethics},
	keywords = {data fabrication, data falsification, fraud, Plagiarism, professional misconduct, scientific research},
	pages = {249--253},
}

@article{whitfield2021,
	title = {Replication {Crisis}},
	volume = {43},
	issn = {0260-9592},
	url = {https://www.lrb.co.uk/the-paper/v43/n19/john-whitfield/replication-crisis},
	abstract = {If a brutally competitive environment helped the best work rise to the top, there might be an argument that the misery...},
	language = {en},
	number = {19},
	urldate = {2023-03-22},
	journal = {London Review of Books},
	author = {Whitfield, John},
	collaborator = {Ritchie, Stuart},
	month = oct,
	year = {2021},
	note = {ISBN: 9781847925657
reviewed-title: Science Fictions: Exposing Fraud, Bias, Negligence and Hype in Science},
	keywords = {Academia, Science technology and mathematics}
}

%%% publication explosion

@misc{hanson2023,
	title = {The strain on scientific publishing},
	url = {http://arxiv.org/abs/2309.15884},
	doi = {10.48550/arXiv.2309.15884},
	abstract = {Scientists are increasingly overwhelmed by the volume of articles being published. Total articles indexed in Scopus and Web of Science have grown exponentially in recent years; in 2022 the article total was 47\% higher than in 2016, which has outpaced the limited growth, if any, in the number of practising scientists. Thus, publication workload per scientist (writing, reviewing, editing) has increased dramatically. We define this problem as the strain on scientific publishing. To analyse this strain, we present five data-driven metrics showing publisher growth, processing times, and citation behaviours. We draw these data from web scrapes, requests for data from publishers, and material that is freely available through publisher websites. Our findings are based on millions of papers produced by leading academic publishers. We find specific groups have disproportionately grown in their articles published per year, contributing to this strain. Some publishers enabled this growth by adopting a strategy of hosting special issues, which publish articles with reduced turnaround times. Given pressures on researchers to publish or perish to be competitive for funding applications, this strain was likely amplified by these offers to publish more articles. We also observed widespread year-over-year inflation of journal impact factors coinciding with this strain, which risks confusing quality signals. Such exponential growth cannot be sustained. The metrics we define here should enable this evolving conversation to reach actionable solutions to address the strain on scientific publishing.},
	urldate = {2024-02-23},
	publisher = {arXiv},
	author = {Hanson, Mark A. and Barreiro, Pablo Gómez and Crosetto, Paolo and Brockington, Dan},
	month = sep,
	year = {2023},
	note = {arXiv:2309.15884 [cs]},
	keywords = {Computer Science - Digital Libraries},
	annote = {Comment: 5 figures, 2 tables, 15 pages + references. Full-res figures at https://doi.org/10.6084/m9.figshare.24203790.v1},
}

%%% reproducible research

@book{desquilbet2019,
  TITLE = {{Vers une recherche reproductible}},
  AUTHOR = {Desquilbet, Lo{\"i}c L. and Granger, Sabrina and Hejblum, Boris and Legrand, Arnaud and Pernot, Pascal and Rougier, Nicolas P. and de Castro Guerra, Elisa and Courbin-Coulaud, Martine and Duvaux, Ludovic and Gravier, Pierre and Le Campion, Gr{\'e}goire and Roux, Solenne and Santos, Fr{\'e}d{\'e}ric},
  URL = {https://hal.science/hal-02144142},
  EDITOR = {Unit{\'e} r{\'e}gionale de formation {\`a} l'information scientifique et technique de Bordeaux},
  PUBLISHER = {{Unit{\'e} r{\'e}gionale de formation {\`a} l'information scientifique et technique de Bordeaux}},
  PAGES = {1-161},
  YEAR = {2019},
  MONTH = May,
  KEYWORDS = {Open source ; Book sprint ; Data sharing ; Open science ; Data reusability ; Research transparency ; Replication crisis ; Reproducible research ; Standardization ; Open data ; Transparence de la recherche ; Recherche reproductible ; Standardisation ; Crise de la r{\'e}plication ; Science ouverte ; R{\'e}utilisation des donn{\'e}es},
  PDF = {https://hal.science/hal-02144142v3/file/20190614_recherche_reproductible.pdf},
  HAL_ID = {hal-02144142},
  HAL_VERSION = {v3},
}

@misc{the_turing_way2022,
	title = {The {Turing} {Way}: {A} handbook for reproducible, ethical and collaborative research},
	shorttitle = {The {Turing} {Way}},
	url = {https://zenodo.org/record/7625728},
	abstract = {The Turing Way: A handbook for reproducible, ethical and collaborative research The Turing Way December 2022 Latest The Turing Way is an open source community-driven guide to reproducible, ethical, inclusive and collaborative data science. The Turing Way book is collaboratively developed by its diverse community of researchers, learners, educators, and other stakeholders. The Turing Way project is openly developed and any and all questions, comments and recommendations are welcome at our github repository: https://github.com/alan-turing-institute/the-turing-way. In 2020, the project underwent a major overhaul categorising chapters into 5 guides on reproducible research, project design, collaboration, communication and ethical research. Additionally, we added a community handbook to document all the practices designed and implemented towards the development of the project and community. This release in 2021 includes additional chapters developed by our contributors across five guides and the community handbook. In addition, all the project documents from the project are provided as they appear on The Turing Way GitHub repository including the Zenodo metadata: https://github.com/alan-turing-institute/the-turing-way. Release log v1.1.0: Zenodo metadata information and additional chapters from Book Dash Dec 2022 v1.0.3: Zenodo metadata information and additional chapters from Book Dash May 2022 v1.0.2: Zenodo metadata information and additional chapters since Book Dash November 2021 v1.0.1: Zenodo metadata information and additional chapters. v1.0.0: Five guide expansion of The Turing Way with a community handbook v0.0.4: Continuous integration chapter merged to main. v0.0.3: Reproducible environments chapter merged to main. v0.0.2: Version control chapter merged to main. v0.0.1: Reproducibility chapter merged to main. Full Changelog: https://github.com/alan-turing-institute/the-turing-way/compare/v1.0.1...v1.0.3 (Previous release: https://github.com/alan-turing-institute/the-turing-way/compare/v0.0.3...v1.0.1) v1.1.0},
	urldate = {2023-03-22},
	publisher = {Zenodo},
	author = {{The Turing Way Community}},
	month = jul,
	year = {2022},
	doi = {10.5281/zenodo.7625728},
	keywords = {collaboration, community, data science, ethics, handbook, reproducibility, research practices}
}

@unpublished{hejblum2020,
	title = {Realistic and {Robust} {Reproducible} {Research} for {Biostatistics}},
	url = {https://hal.inria.fr/hal-03100421},
	abstract = {The complexity of analysis pipelines in biomedical sciences poses a severe challenge for the transparency and reproducibility of results. Researchers are increasingly incorporating software development technologies and methods into their analyses, but this is a quickly evolving landscape and teams may lack the capabilities to set up their own complex IT infrastructure to aid reproducibility. Basing a reproducible research strategy on readily available solutions with zero or low set-up costs whilst maintaining technological flexibility to incorporate domain-specific software tools is therefore of key importance. We outline a practical approach for robust reproducibility of analysis results. In our examples, we rely exclusively on established open-source tools and free services. Special emphasis is put on the integration of these tools with best practices from software development and free online services for the biostatistics domain.},
	urldate = {2021-04-20},
	author = {Hejblum, Boris P. and Kunzmann, Kevin and Lavagnini, Ennio and Hutchinson, Anna and Robertson, David and Jones, Sacha and Eckes-Shephard, Annemarie},
	year = {2020},
	doi = {10.20944/preprints202006.0002.v1},
	keywords = {Biostatistics, Data management, Reproducibility, Workflow automation},
	annote = {working paper or preprint},
}

%%% data repository

@misc{zenodo,
  doi = {10.25495/7GXK-RD71},
  url = {https://www.zenodo.org/},
  author = {{European Organization For Nuclear Research} and {OpenAIRE}},
  keywords = {FOS: Physical sciences, Publication, Dataset},
  language = {en},
  title = {Zenodo},
  publisher = {CERN},
  year = {2013}
}

@article{foster2017,
	title = {Open {Science} {Framework} ({OSF})},
	volume = {105},
	issn = {1536-5050},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5370619/},
	doi = {10.5195/jmla.2017.88},
	number = {2},
	urldate = {2023-03-22},
	journal = {Journal of the Medical Library Association : JMLA},
	author = {Foster, Erin D. and Deardorff, Ariel},
	month = apr,
	year = {2017},
	pmid = {null},
	pmcid = {PMC5370619},
	pages = {203--206}
}

%%% open access

@article{ancion2022,
	title = {Action {Plan} for {Diamond} {Open} {Access}},
	url = {https://zenodo.org/record/6282403},
	doi = {10.5281/zenodo.6282403},
	abstract = {Science Europe, cOAlition S, OPERAS, and the French National Research Agency (ANR) present an Action Plan for Diamond Open Access to further develop and expand a sustainable, community-driven Diamond OA scholarly communication ecosystem. It focuses on efficiency, quality standards, capacity building, and sustainability, and it addresses the alignment and development of common resources for the whole Diamond OA ecosystem, including journals and platforms, while respecting the cultural, multilingual, and disciplinary diversity that constitutes the strength of the sector. The Action Plan intends to create an inclusive worldwide community that has the tools to strengthen existing Diamond OA journals and platforms and increase their visibility.},
	language = {eng},
	urldate = {2023-03-22},
	author = {Ancion, Zoé and Borrell-Damián, Lidia and Mounier, Pierre and Rooryck, Johan and Saenen, Bregt},
	month = mar,
	year = {2022},
	note = {Publisher: Zenodo},
	keywords = {Diamond Open Access, Open Access}
}

@techreport{planS,
  TITLE = {{Recommendations for Plan S implementation by the ANR}},
  AUTHOR = {Publications, Coll{\`e}ge and {\'E}dition Scientifique Ouverte, Groupe d'Expertise and Construire La Bibliodiversit{\'e}, Groupe Projet},
  URL = {https://hal-lara.archives-ouvertes.fr/hal-03640413},
  TYPE = {Research Report},
  PAGES = {8 p.},
  INSTITUTION = {{Comit{\'e} pour la science ouverte}},
  YEAR = {2019},
  MONTH = Jan,
  DOI = {10.52949/18},
  KEYWORDS = {bibliodiversity ; open access ; open science ; scientific publication ; Plan S ; open archive ; copyright ; recommendations ; diamond journal ; bibliodversit{\'e} ; acc{\`e}s ouvert ; science ouverte ; publication scientifique ; Plan S ; archive ouverte ; droit d'auteur ; recommandations ; mod{\`e}le diamant},
  PDF = {https://hal-lara.archives-ouvertes.fr/hal-03640413/file/Plan-S-Pre%CC%81conisations-EN-2019.pdf},
  HAL_ID = {hal-03640413},
  HAL_VERSION = {v1},
}

%%% programming

@article{knuth1984,
	title = {Literate programming},
	volume = {27},
	number = {2},
	journal = {The Computer Journal},
	author = {Knuth, Donald Ervin},
	year = {1984},
	note = {Publisher: Oxford University Press},
	pages = {97--111}
}
